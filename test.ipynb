{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import io\n",
    "project_id = \"interseguro-data\"\n",
    "client = bigquery.Client(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "TABLE_NAME\n",
    ",COLUMN_NAME\n",
    ",COLUMN_ID\n",
    ",1 AS INDICADOR\n",
    "FROM `interseguro-data.acsele_data.ALL_TAB_COLUMNS_raw`\n",
    "WHERE TABLE_NAME IN ('RECIBIRDOCUMENTO', 'DERIVARCOMERCIAL')\n",
    "ORDER BY TABLE_NAME,COLUMN_ID ASC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlbigquery(filename):\n",
    "    with open(filename,\"r\") as file:\n",
    "        statement = file.readlines()\n",
    "        statement = \" \".join(statement)\n",
    "    print(f\" {filename}\")\n",
    "    return statement\n",
    "\n",
    "def read_table_bq(sql):\n",
    "    df = pd.read_gbq(sql, project_id=project_id, dialect='standard')\n",
    "    return df\n",
    "\n",
    "def load_data(df,filename):\n",
    "    par_project_output = 'interseguro-data'\n",
    "    par_bucket_output = 'interseguro-datalake-prod'\n",
    "    client_output = storage.Client(par_project_output)\n",
    "    bucket_output = client_output.bucket(par_bucket_output)\n",
    "    bytes_writer = io.BytesIO()\n",
    "    df_bytes = df.to_parquet(bytes_writer,engine=\"pyarrow\")\n",
    "    data_length = bytes_writer.tell()\n",
    "    print(f\"[INFO] size file : {data_length}\")\n",
    "    bytes_writer.seek(0)\n",
    "    blob_n = bucket_output.blob(f\"SPARK_TABLE/ACSELE/{filename}/{filename}.parquet\")\n",
    "    blob_n.upload_from_string(\n",
    "        data=bytes_writer.getvalue(),\n",
    "        content_type='application/octet-stream',\n",
    "        client=client_output\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jberriot\\AppData\\Local\\Temp\\ipykernel_8648\\52575413.py:9: FutureWarning: read_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.read_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.read_gbq\n",
      "  df = pd.read_gbq(sql, project_id=project_id, dialect='standard')\n"
     ]
    }
   ],
   "source": [
    "df = read_table_bq (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DERIVARCOMERCIAL', 'RECIBIRDOCUMENTO'], dtype='object', name='TABLE_NAME')\n"
     ]
    }
   ],
   "source": [
    "pivot_df = df.pivot(index='COLUMN_NAME', columns='TABLE_NAME', values='INDICADOR')\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "pivot_df.to_excel('testeo.xlsx')\n",
    "columnas = pivot_df.columns\n",
    "print(columnas)\n",
    "df_temp = pd.read_excel('testeo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_condicion(row):\n",
    "    resultado = {}\n",
    "    for col in columnas:\n",
    "        if row.name == num_filas -1 :\n",
    "            resultado[col] = ',' + row['COLUMN_NAME'] + '\\nFROM INTERSEGURO.'+col + '\\nUNION ALL ' \n",
    "        elif row[col] == 1:\n",
    "            #resultado[col] = 'SELECT \\n'+ row['COLUMN_NAME'] if row.name == 0 else ',' + row['COLUMN_NAME']\n",
    "            resultado[col] = f\"SELECT \\n'{col}' AS ESTADO \\n,\"+ row['COLUMN_NAME'] if row.name == 0 else ',' + row['COLUMN_NAME']\n",
    "        else:\n",
    "            resultado[col] = 'SELECT NULL AS ' + row['COLUMN_NAME'] if row.name == 0 else ',NULL AS ' + row['COLUMN_NAME']\n",
    "    return pd.Series(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file(df):\n",
    "    with open('output.sql', 'w') as file:\n",
    "        for col in columnas:\n",
    "            for value in df[col]:\n",
    "                file.write(str(value) + '\\n')\n",
    "                \n",
    "num_filas = df_temp.shape[0]\n",
    "nuevas_columnas = df_temp.apply(aplicar_condicion, axis=1)\n",
    "df_t = pd.concat([df_temp['COLUMN_NAME'], nuevas_columnas], axis=1)                \n",
    "generate_file(df_t)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
